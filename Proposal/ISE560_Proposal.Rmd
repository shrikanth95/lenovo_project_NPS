---
title: "ISE 560 Project Proposal"
author: "Shawn Markham, Melissa Wong, Shrikanth Yadav & Lekhana Yennam"
date: \today
header-includes:
   - \usepackage{fontspec}
   - \setmainfont{Times New Roman}
   - \usepackage{setspace}
   - \onehalfspacing
   - \usepackage{enumitem}
   - \usepackage{float}
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    fig_caption: true
fontsize: 12pt
geometry: margin=1in 
urlcolor: blue
---

```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE)
#knitr::opts_chunk$set(out.width="50%")
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

library(tidyverse)
library(lubridate)
library(grid)
library(gridExtra)
```

# Overview

Lenovo is an international company and a market leader in the personal computer industry.  One tool Lenovo relies upon in assessing customer satisifaction is Net Promoter Score (NPS); this is a standard metric used by major corporations across many industries.  However, latency is a limitation because it can take several months to aggregate sufficient data to calculate NPS.  Therefore Lenovo wants to determine if near-real-time data such as customer ratings and comments from websites and telemetry can accurately predict NPS.  If accurate predictions are possible, then Lenovo can potentially take actions (e.g., deploying out of cycle software patches) more quickly which will lead to higher NPS scores in the future.

A high-level outline of how we propose to approach this problem is as follows:
\begin{enumerate}[nosep]
  \item Fit a linear model for NPS as a function of Product Sentiment Index (PSI) and other key variables.
  \item Use linear model to generate a predicted NPS transition matrix
  \item The predicted NPS transition matrix is an input to the Markov Decision Process (MDP)
  \item Use MDP to recommended actions based on the transition matrix, rewards, etc.
\end{enumerate}

## Model

We propose developing a linear regression model where NPS is the response and PSI is a key explanatory variable. Based on a preliminary analysis of the data (see Section \ref{data_analysis}), star rating, product series and telemetry data are additional potential explanatory variables. The PSI will be modeled as a stochastic process.  Therefore, the NPS prediction from the model will also be a stochastic process.

## Metrics

We propose using k-fold cross validation to evaluate candidate models as follows:
\begin{enumerate}[nosep]
  \item Randomly shuffle the data and split into k-groups.
  \item For each group
  \begin{enumerate}[nosep]
    \item Reserve the current group as the test data set.
    \item Fit candidate model(s) to the remaining k-1 data sets and perform variable selection.
    \item Assess model fit with the test data set.  Note we will assess both the predicted NPS scores and predicted NPS transition matrix against the test data set NPS scores and NPS transition matrix.
  \end{enumerate}
\end{enumerate}

<!-- Assuming we develop multiple candidate models, then we will use the results from the cross-validation to  make a final model recommendation.  This approach gives us additional flexibility; for example, the final recommendation may be two models with different explanatory variables for the Commercial and Consumer segments versus a single model with the same explanatory variables for both business segments. -->

# NPS & Telemetry
   Net Promotor Score (NPS) is a management tool that measures customer satisfaction, as well as customer loyalty. The score is based entirely on the customer’s response to the question “How likely are you to recommend this product (or service) to someone else?” Their response is a number on the scale of zero (being the least likely) to ten (being the most likely). Companies then categorize the customers based off the scores they inputted. If a customer’s NPS response score was between a nine and a ten, the customer is called a promoter. If the customer’s response was low, between zero and six, they are called a detractor. The company’s NPS score is calculated by subtracting the percentage of detractors from the percentage of promoters. Every industry has a different NPS average and this number can give a company a good indication of how loyal their customers are compared to other companies. Customer loyalty is crucial because companies spend less money keeping current customers than marketing to attract new customers. Within the laptop and tablet industry, the average NPS score is a 40. 
   
   Telemetry data is system performance data that is captured as soon as a device is turned on. This data is captured by Microsoft and then sent to Lenovo. Lenovo can then analyze this data to determine meaningful information about their machines. Telemetry is crucial within the laptop industry because it gives companies insight on which features their customers are using the most, enabling them to determine the most important features and shape future models based off of these statistics. Analyzing Telemetry data can also help Lenovo determine which devices are malfunctioning or experiencing bugs. For instance, if the data shows that seventy percent of Lenovo ThinkPad’s are crashing every two hours, Lenovo may need to provide some type of update or even recall the machine. In this same example where a customer is experiencing crashes every two hours, it is likely that they will answer the question “How likely are you to recommend this product (or service) to someone else?” with a low NPS score and be identified as a detractor. For this reason, telemetry has a great potential for predicting NPS score.

# Key Variables and Parameters

Based on the preliminary data analysis key variables include the following:

  - Product Sentiment Index (PSI)
  - Star rating
  - Business Segment (i.e., Commercial and Consumer)
  - Product Family/Series
  - Battery Life

Key parameters include the following:

  - PSI Transition Probabilities (estimated from the data)
  - ??
  
# Critical Uncertainties

Identify and describe critical uncertainties within the model with regards to parameters and decision variables. Identify those uncertainties that may be dynamic (stochastic). 

  - Three variables of interest
    - pNPS 
    - PSI and Star rating
    - Telemetry
  - Discretize probabilities. 
  - We are given time series data for two years.  
  
# Markov Decision Process

The states that can be used to develop a Markov Chain include NPS states and star rating states. We have categorized NPS into five states.\textsuperscript{\ref{refs}}

State              | Range          |
----------         | -------------- | 
Very Low NPS       | -100-8         |
Moderately Low NPS |  8-35          |
Normal  NPS        |  35-45         |
Moderately High NPS|  45-60         |
Very High NPS      |  60-100        |
Negative Star      |  1,2           |
Neutral Star       |  3             | 
Positive Star      |  4,5           |


# Preliminary Data Analysis \label{data_analysis}


Segment    | Total Products | w/Sentiment and NPS | w/Battery 
---------- | -------------- | ------------ | ------- 
Consumer   | 487            |      74          | TBD     
Commercial | 238            |      46          | TBD     
SMB        |   59           |      18          | TBD     

Figure \ref{fig:overall_summary} provides a broad overview of the trends within pNPS, PIS and the star rating.  Note that pNPS was calculated using the given formula.  PSI was calculated by:

\begin{equation}
PSI = \frac{\text{Positive mentions}- \text{Negative mentions}}{\text{Positive mentions}+ \text{Negative mentions}}\times 100.
\end{equation}
The period of interest is one month.  Star ratings are averaged over a month for each segment. In order to observe trends, star rating is scaled by a multiplicative factor of 20.  Further note that as ownership durating is avaiable only for the surveys, the PIS and Star rating per segment will be identical in each facet.  
  
\begin{figure}[t]
  \centering
  \includegraphics[width = 0.48\textwidth]{Figures/all_metric_summary_consumer.pdf}
  \includegraphics[width = 0.48\textwidth]{Figures/all_metric_summary_commercial.pdf}
  \caption{Trends in the pNPS, PIS and average star rating when downsamped at 1-month intervals.}
  \label{fig:overall_summary}
\end{figure}


## Epochs

We looked at the evolution of both PSI and NPS over various time periods.  Figure \ref{fig:comm_epoch} is an example of PSI and NPS for commercial products over monthly and weekly epochs.  The weekly epochs show significant changes in both PSI and NPS from week to week.  Weekly is too fine-grained to be of practical use since it would require Lenovo to take an action within hours or days at most to have any meaningful impact.  On the other hand, the monthly epochs show less drastic changes and now the time scale for Lenovo to take action is more reasonable (days to a couple of weeks).

```{r}
# Read in all sentiment data
sentiment <- read.csv("../RawData/CID_Web_Sentiment.csv")

# Read in all NPS data
survey <- read.csv("../RawData/Lenovo_Survey_Data_pNPS_Rev2.csv")

# Filter Commercial data
sentiment.comm.all <- sentiment %>%
  filter(Business.Group == "LENOVO - COMMERCIAL") %>%
  mutate(ProductName = I(toupper(as.character(Product)))) 


survey.comm.all <- survey %>%
  filter(Segment == "Lenovo - Commercial") %>%
  mutate(ProductName = I(toupper(as.character(Product))), 
         SeriesName = I(toupper(as.character(Series)))) %>%
  mutate(NPS = as.numeric(as.character(Product.NPS))) %>%
  drop_na(NPS)

# Get set of Commercial products
comm.prods.df1 <- sort(unique(sentiment.comm.all$ProductName))
comm.prods.df2 <- sort(unique(survey.comm.all$ProductName))
comm.prods <- data.frame(name = I(unique(c(comm.prods.df1, comm.prods.df2)))) %>%
  mutate(have_sentiment = name %in% comm.prods.df1,
         have_survey = name %in% comm.prods.df2) %>%
  filter(have_sentiment & have_survey)

# Filter to only consider products with both sentiment and survey data
sentiment.comm <- sentiment.comm.all  %>%
  filter(ProductName %in% comm.prods$name)

survey.comm <- survey.comm.all %>%
  filter(ProductName %in% comm.prods$name)
```

```{r fig.cap="\\label{fig:comm_epoch}Commercial Sentiment and NPS Data", fig.pos="H", fig.height=2}
####################################################
# Calculate PSI by month for all Commercial products
####################################################
comm.psi.month <- sentiment.comm %>%
  group_by(month = floor_date(as.Date(Comment.Date, format = "%m/%d/%y"), unit = "month")) %>%
  summarise(pos = sum(Sentiment == "POSITIVE"),
            neg = sum(Sentiment == "NEGATIVE")) %>%
  mutate(psi = 100 * (pos - neg)/(pos +  neg))

# Calculate NPS by month for all Commercial producs
comm.nps.month <- survey.comm %>%
  group_by(month = floor_date(as.Date(Date.Survey, format = "%m/%d/%Y"), unit = "month")) %>%
  summarise(promoter = sum(NPS >= 9),
            detractor = sum(NPS <= 6),
            total = n()) %>%
  mutate(nps = 100 * (promoter - detractor) / total)

p1 <- ggplot() +
  geom_line(data = comm.psi.month, mapping = aes(x=month, y=psi, color="PSI")) +
  geom_line(data = comm.nps.month, mapping = aes(x=month, y=nps, color="NPS")) +
  #labs(title="By Month") +
  theme(legend.position = "none")

###################################################
# Calculate PSI by week for all Commercial products
###################################################
comm.psi.week <- sentiment.comm %>%
  group_by(week = floor_date(as.Date(Comment.Date, format = "%m/%d/%y"), unit = "week")) %>%
  summarise(pos = sum(Sentiment == "POSITIVE"),
            neg = sum(Sentiment == "NEGATIVE")) %>%
  mutate(psi = 100 * (pos - neg)/(pos +  neg))

# Calculate NPS by month for all Commercial producs
comm.nps.week <- survey.comm %>%
  group_by(week = floor_date(as.Date(Date.Survey, format = "%m/%d/%Y"), unit = "week")) %>%
  summarise(promoter = sum(NPS >= 9),
            detractor = sum(NPS <= 6),
            total = n()) %>%
  mutate(nps = 100 * (promoter - detractor) / total)

p2 <- ggplot() +
  geom_line(data = comm.psi.week, mapping = aes(x=week, y=psi, color="PSI")) +
  geom_line(data = comm.nps.week, mapping = aes(x=week, y=nps, color="NPS")) 
  #labs(title="By Week") +
  #theme(legend.position = "bottom")

grid.arrange(p1, p2, ncol=2, widths=c(2.4, 3.0))
```

## Telemetry

# References \label{refs}

https://www.satmetrix.com/wp-content/uploads/2019/04/2019-Benchmarks.pdf

https://delighted.com/nps-benchmarks


